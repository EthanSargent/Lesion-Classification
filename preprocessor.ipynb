{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipdb\n",
    "import imageio\n",
    "import cv2\n",
    "import argparse\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from numpy.random import shuffle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multiclass_symlinks(data_dir, descriptions_dir, raw_images_dir):\n",
    "    ''' We want to set up a folder structure for input into Pytorch's\n",
    "        ImageFolder utility. Therefore the data must be broken down like\n",
    "        data_dir/\n",
    "            train/\n",
    "                class1/\n",
    "                class2/\n",
    "                .\n",
    "                .\n",
    "                .\n",
    "            val/\n",
    "                class1/\n",
    "                class2/\n",
    "                .\n",
    "                .\n",
    "                .\n",
    "        Rather than copy all our data into a new structure for our data, \n",
    "        we use symlinks from the already existing raw data files.\n",
    "        \n",
    "        This function creates a 90-10 train-test split.\n",
    "    '''\n",
    "    description_paths, image_paths, class_dict = get_multiclass_paths(descriptions_dir,\\\n",
    "                                                          raw_images_dir)\n",
    "    n = len(description_paths)\n",
    "    train_image_paths = [image_path\\\n",
    "             for image_path in image_paths[:int(-n/10)]]\n",
    "    val_image_paths = [image_path\\\n",
    "             for image_path in image_paths[int(-n/10):]]\n",
    "    paths={'train':train_image_paths, 'val':val_image_paths}\n",
    "    \n",
    "    for phase in paths:\n",
    "        for lesion_class in class_dict:\n",
    "            os.mkdir(join(data_dir, phase, lesion_class))\n",
    "         \n",
    "        for path in paths[phase]:\n",
    "            ID = paths[phase][16:28]\n",
    "            with open (join(descriptions_dir, ID), \"r\") as file:\n",
    "                data = file.read().replace('\\n', '')\n",
    "                diagnosis = json.loads(data)['meta']['clinical']['diagnosis']\n",
    "            os.symlink(path, join(data_dir, phase, diagnosis, path[16:]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multiclass_paths(descriptions_dir, raw_images_dir):\n",
    "    image_IDs = []\n",
    "    diagnoses = []\n",
    "    for ID in listdir(descriptions_dir):\n",
    "        with open (join(descriptions_dir, ID), \"r\") as file:\n",
    "            data = file.read().replace('\\n', '')\n",
    "            try:\n",
    "                diagnoses.append(json.loads(data)['meta']['clinical']['diagnosis'])\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "    cnt = Counter(diagnoses)\n",
    "    del cnt[None]\n",
    "    class_dict = {diagnosis:count for diagnosis, count in cnt.most_common(9)}\n",
    "    classes = list(class_dict.keys())\n",
    "    \n",
    "    for ID in listdir(descriptions_dir):\n",
    "        with open (join(descriptions_dir, ID), \"r\") as file:\n",
    "            data = file.read().replace('\\n', '')\n",
    "            try:\n",
    "                diagnosis = json.loads(data)['meta']['clinical']['diagnosis']\n",
    "                if diagnosis in classes:\n",
    "                    image_IDs.append(ID)\n",
    "            except:\n",
    "                continue\n",
    "    image_IDs.sort()\n",
    "    \n",
    "    image_paths = [join(raw_images_dir, f) for f in listdir(raw_images_dir)\\\n",
    "                       if (f[:12] in image_IDs)]\n",
    "    image_paths.sort()\n",
    "\n",
    "    description_paths = [join(descriptions_dir, f) for f in image_IDs]\n",
    "    \n",
    "    # permuting the dataset removes some of the class imbalance among the chunks\n",
    "    np.random.seed(20)\n",
    "    X = np.asarray([description_paths, image_paths]).T\n",
    "    shuffle(X)\n",
    "    description_paths = X[:,0]\n",
    "    image_paths= X[:,1]\n",
    "    \n",
    "    return description_paths, image_paths, class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paths(descriptions_dir, raw_images_dir): \n",
    "    # we want a list of the IDs of images that have a useful binary label\n",
    "    # as benign or malignant\n",
    "    image_IDs = []\n",
    "    for ID in listdir(descriptions_dir):\n",
    "        with open (join(descriptions_dir, ID), \"r\") as file:\n",
    "            data = file.read().replace('\\n', '')\n",
    "            try:\n",
    "                json.loads(data)['meta']['clinical']['benign_malignant']\n",
    "                image_IDs.append(ID)\n",
    "            except:\n",
    "                continue\n",
    "    image_IDs.sort()\n",
    "    \n",
    "    # compute the list of image paths for all images that have useful\n",
    "    # binary label (i.e., those in image_IDs [without .jpeg/.png extension])\n",
    "    image_paths = [join(raw_images_dir, f) for f in listdir(raw_images_dir)\\\n",
    "                       if (f[:12] in image_IDs)]\n",
    "    image_paths.sort()\n",
    "\n",
    "    description_paths = [join(descriptions_dir, f) for f in image_IDs]\n",
    "    \n",
    "    # permuting the dataset removes some of the class imbalance among the chunks\n",
    "    np.random.seed(20)\n",
    "    X = np.asarray([description_paths, image_paths]).T\n",
    "    shuffle(X)\n",
    "    description_paths = X[:,0]\n",
    "    image_paths= X[:,1]\n",
    "    \n",
    "    return description_paths, image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chunks(chunks, data_dir, descriptions_dir, raw_images_dir, aspect_ratio=2/3):\n",
    "    ''' Processes the raw data into 'chunks' number of image and label\n",
    "        PyTorch tensors, to be stored in the 'data_dir' directory. If\n",
    "        'estimate_aspect_ratio' is passed, the median aspect ratio is\n",
    "        computed prior to chunk loading. All images are reshaped to\n",
    "        (300, 300/aspect_ratio) in order to standardize input to the\n",
    "        neural network.\n",
    "    '''\n",
    "    description_paths, image_paths = get_paths(descriptions_dir, raw_images_dir)\n",
    "        \n",
    "    n = len(description_paths)\n",
    "    chunk_size = n//chunks\n",
    "    \n",
    "    for chunk in range(chunks):\n",
    "        image_numbers = list(range(chunk*chunk_size, min((chunk+1)*chunk_size, n)))\n",
    "        X = load_image_chunk(image_numbers, image_paths, aspect_ratio)\n",
    "        Y = load_label_chunk(image_numbers, description_paths)\n",
    "        torch.save(X, data_dir + '/images-' + str(chunk) + '.pt')\n",
    "        torch.save(Y, data_dir + '/labels-' + str(chunk) + '.pt')\n",
    "        print(\"Finished chunk \" + str(chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute an estimate of the mean aspect ratio\n",
    "def compute_aspect_ratio(image_paths):\n",
    "    ratios = []\n",
    "    for filename in image_paths:\n",
    "        x = imageio.imread(image_paths)\n",
    "        ratios.append(x.shape[0]/x.shape[1])\n",
    "    aspect_ratio = np.mean(np.asarray(ratios))\n",
    "    return aspect_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_chunk(image_numbers, image_paths, aspect_ratio):\n",
    "    X = torch.empty(size=(len(image_numbers), 300, int(300/aspect_ratio), 3))\n",
    "    for sample_idx, idx in enumerate(tqdm(image_numbers)):\n",
    "        # resize the images to the computed mean aspect ratio using cv2\n",
    "        img = cv2.imread(image_paths[idx])\n",
    "        res = cv2.resize(img, dsize=(int(300/aspect_ratio), 300),\\\n",
    "                         interpolation=cv2.INTER_CUBIC)\n",
    "        X[sample_idx] = torch.tensor(res)\n",
    "    Y = torch.tensor([1 if diagnosis=='malignant' else 0 for diagnosis in Y])\n",
    "    X = X.permute(0,3,1,2)\n",
    "    return X,Y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
