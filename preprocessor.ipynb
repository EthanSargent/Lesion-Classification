{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipdb\n",
    "import imageio\n",
    "import cv2\n",
    "import argparse\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from tqdm import tqdm\n",
    "from numpy.random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chunks(chunks, images_dir, labels_dir, raw_images_dir, descriptions_dir):\n",
    "    descriptions_path = 'raw_data/Descriptions'\n",
    "\n",
    "    # we only want the images that have a description\n",
    "    image_IDs = [f for f in listdir(descriptions_path)\\\n",
    "                        if isfile(join(descriptions_path, f))]\n",
    "    \n",
    "    # filter out the images with missing or opaquely-formatted clinical data\n",
    "    unusable = []\n",
    "    for ID in image_IDs:\n",
    "        with open (join(descriptions_path, ID), \"r\") as file:\n",
    "            data = file.read().replace('\\n', '')\n",
    "            try:\n",
    "                json.loads(data)['meta']['clinical']['benign_malignant']\n",
    "            except:\n",
    "                unusable.append(ID)\n",
    "\n",
    "    image_IDs = list(set(image_IDs) - set(unusable))\n",
    "    image_IDs.sort()\n",
    "    \n",
    "    # a little redundancy here to ensure that each image with usable clinical data\n",
    "    # is also represented in the raw_data/Images folder.\n",
    "    images_path = 'raw_data/Images'\n",
    "    image_filenames = [join(images_path, f) for f in listdir(images_path)\\\n",
    "                       if (f[:12] in image_IDs)]\n",
    "    image_filenames.sort()\n",
    "\n",
    "    descriptions_path = 'raw_data/Descriptions'\n",
    "    description_filenames = [join(descriptions_path, f) for f in image_IDs]\n",
    "    \n",
    "    # permuting the dataset removes some of the class imbalance among the chunks\n",
    "    np.random.seed(20)\n",
    "    X = np.asarray([description_filenames, image_filenames]).T\n",
    "    shuffle(X)\n",
    "    description_filenames = X[:,0]\n",
    "    image_filenames = X[:,1]\n",
    "    \n",
    "    if compute_aspect_ratio:\n",
    "        aspect_ratio = estimate_aspect_ratio(image_filenames)\n",
    "    else:\n",
    "        aspect_ratio = 0.7105451408210631\n",
    "\n",
    "    n = len(image_IDs)\n",
    "    chunk_size = n//chunks\n",
    "    \n",
    "    for chunk in range(chunks):\n",
    "        load_chunk(chunk, image_filenames, description_filenames, chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute an estimate of the mean aspect ratio\n",
    "def estimate_aspect_ratio(image_filenames):\n",
    "    ratios = []\n",
    "    np.random.seed(20)\n",
    "    sample = np.random.choice(image_filenames, 1000)\n",
    "    for filename in sample:\n",
    "        x = imageio.imread(filename)\n",
    "        ratios.append(x.shape[0]/x.shape[1])\n",
    "    aspect_ratio = np.mean(np.asarray(ratios))\n",
    "    return aspect_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chunk(chunk, image_filenames, description_filenames, chunk_size):\n",
    "    image_numbers = list(range(chunk*chunk_size, (chunk+1)*chunk_size))\n",
    "    if chunk==9:\n",
    "        image_numbers = list(range(chunk*chunk_size, n))\n",
    "\n",
    "    X = torch.empty(size=(len(image_numbers), 216, int(216/aspect_ratio), 3))\n",
    "    Y = []\n",
    "    for sample_idx, idx in enumerate(tqdm(image_numbers)):\n",
    "        # resize the images to the computed mean aspect ratio using cv2\n",
    "        img = cv2.imread(image_filenames[idx])\n",
    "        res = cv2.resize(img, dsize=(int(216/aspect_ratio), 216),\\\n",
    "                         interpolation=cv2.INTER_CUBIC)\n",
    "        X[sample_idx] = torch.tensor(res)\n",
    "        with open (description_filenames[idx], \"r\") as file:\n",
    "            data = file.read().replace('\\n', '')\n",
    "            Y.append(json.loads(data)['meta']['clinical']['benign_malignant'])\n",
    "    Y = torch.tensor([1 if diagnosis=='malignant' else 0 for diagnosis in Y])\n",
    "    X = X.permute(0,3,1,2)\n",
    "    print(\"Finished chunk \" + str(chunk))\n",
    "    torch.save(X, 'data/images-' + str(chunk) + '.pt')\n",
    "    torch.save(Y, 'data/labels-' + str(chunk) + '.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confirm_arguments(args):\n",
    "    print('You have decided to do the following:')\n",
    "    if args.chunks is None:\n",
    "        print('Process data in 10 chunks')\n",
    "    else:\n",
    "        print('Process data in {0} elements'.format(args.chunks))\n",
    "\n",
    "    if args.images_dir is None:\n",
    "        print('Images tensor chunks will be downloaded to \"data\" directory.')\n",
    "    else:\n",
    "        print('Images tensor chunks be downloaded to \"{0}\" directory.'.format(args.images_dir))\n",
    "        \n",
    "    if args.labels_dir is None:\n",
    "        print('Images labels will be downloaded to \"data\" directory.')\n",
    "    else:\n",
    "        print('Images labels will be downloaded to \"{0}\" directory.'.format(args.labels_dir))\n",
    "\n",
    "    res = input('Do you confirm your choices? [Y/n] ')\n",
    "\n",
    "    while res not in ['y', '', 'n']:\n",
    "        res = input('Invalid input. Do you confirm your choices? [Y/n] ')\n",
    "    if res in ['y', '']:\n",
    "        return True\n",
    "    if res == 'n':\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args(args):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--chunks', type=int,\n",
    "                        help='The number of chunks into which the raw image dataset will be broken up.'\n",
    "                        'The last chunk will be used for testing. If this argument is passed, the'\n",
    "                        'the entire dataset will be re-partitioned.', default=10)\n",
    "    parser.add_argument('--images_dir', type=int,\n",
    "                        help='The directory into which the image tensors chunks will be downloaded.',\\\n",
    "                        default='data')\n",
    "    parser.add_argument('--labels_dir', type=int,\n",
    "                        help='The directory into which the labels for the corresponding image tensor chunk'\n",
    "                        ' will be downloaded.', default='data')\n",
    "    parser.add_argument('--raw_images_dir', type=int,\n",
    "                        help='Where the raw images are located.',\\\n",
    "                        default=join('raw_data','Images'))\n",
    "    parser.add_argument('--descriptions_dir', type=int,\n",
    "                        help='Where the verbose image descriptions are located.',\\\n",
    "                        default=join('raw_data','Descriptions'))\n",
    "    parser.add_argument('--aspect_ratio', help='Whether to recompute the mean aspect ratio.', action=\"store_true\")\n",
    "    parsed_args = parser.parse_args(args)\n",
    "    return parsed_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    args = parse_args(args)\n",
    "    has_confirmed = confirm_arguments(args)\n",
    "\n",
    "    if has_confirmed:\n",
    "        process_chunks(chunks=args.chunks, images_dir=args.images_dir, labels_dir=args.labels_dir,\\\n",
    "                      raw_images_dir = args.raw_images_dir, descriptions_dir = args.descriptions_dir,\n",
    "                      aspect_ratio = args.aspect_ratio)\n",
    "    else:\n",
    "        print('Exiting without downloading anything')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
